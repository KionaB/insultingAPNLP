{
 "cells": [
  {
   "cell_type": "code",
   "id": "91714f94-0cb7-43e6-80a2-892a797ac25a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-12-01T15:22:05.783374Z",
     "start_time": "2025-12-01T15:21:28.637661Z"
    }
   },
   "source": [
    "!pip install tabulate\n",
    "!pip install sentence_transformers"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tabulate in c:\\programdata\\anaconda3\\lib\\site-packages (0.8.10)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting sentence_transformers\n",
      "  Downloading sentence_transformers-5.1.2-py3-none-any.whl (488 kB)\n",
      "     -------------------------------------- 488.0/488.0 kB 7.6 MB/s eta 0:00:00\n",
      "Collecting huggingface-hub>=0.20.0\n",
      "  Downloading huggingface_hub-1.1.7-py3-none-any.whl (516 kB)\n",
      "     ------------------------------------- 516.2/516.2 kB 16.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence_transformers) (1.2.1)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence_transformers) (4.64.1)\n",
      "Requirement already satisfied: Pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence_transformers) (9.4.0)\n",
      "Collecting typing_extensions>=4.5.0\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "     ---------------------------------------- 44.6/44.6 kB ? eta 0:00:00\n",
      "Collecting transformers<5.0.0,>=4.41.0\n",
      "  Downloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
      "     ---------------------------------------- 12.0/12.0 MB 6.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence_transformers) (1.10.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence_transformers) (1.12.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (22.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0)\n",
      "Collecting shellingham\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Collecting typer-slim\n",
      "  Downloading typer_slim-0.20.0-py3-none-any.whl (47 kB)\n",
      "     ---------------------------------------- 47.1/47.1 kB ? eta 0:00:00\n",
      "Collecting httpx<1,>=0.23.0\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "     ---------------------------------------- 73.5/73.5 kB 4.0 MB/s eta 0:00:00\n",
      "Collecting hf-xet<2.0.0,>=1.2.0\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-win_amd64.whl (2.9 MB)\n",
      "     ---------------------------------------- 2.9/2.9 MB 26.6 MB/s eta 0:00:00\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Downloading fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
      "     ---------------------------------------- 201.0/201.0 kB ? eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.9.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->sentence_transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2022.7.9)\n",
      "Collecting safetensors>=0.4.3\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-win_amd64.whl (341 kB)\n",
      "     ---------------------------------------- 341.4/341.4 kB ? eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (1.23.5)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2.28.1)\n",
      "Collecting huggingface-hub>=0.20.0\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "     -------------------------------------- 566.1/566.1 kB 9.0 MB/s eta 0:00:00\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "     ---------------------------------------- 2.7/2.7 MB 18.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sentence_transformers) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sentence_transformers) (2.2.0)\n",
      "Requirement already satisfied: anyio in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence_transformers) (3.5.0)\n",
      "Collecting httpcore==1.*\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.8/78.8 kB ? eta 0:00:00\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence_transformers) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence_transformers) (2023.5.7)\n",
      "Collecting h11>=0.16\n",
      "  Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (2.0.4)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from typer-slim->huggingface-hub>=0.20.0->sentence_transformers) (8.0.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence_transformers) (1.2.0)\n",
      "Installing collected packages: typing_extensions, safetensors, fsspec, huggingface-hub, tokenizers, transformers, sentence_transformers\n",
      "Successfully installed fsspec-2025.10.0 huggingface-hub-0.36.0 safetensors-0.7.0 sentence_transformers-5.1.2 tokenizers-0.22.1 transformers-4.57.3 typing_extensions-4.15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts hf.exe, huggingface-cli.exe and tiny-agents.exe are installed in 'C:\\Users\\kiona\\AppData\\Roaming\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts transformers-cli.exe and transformers.exe are installed in 'C:\\Users\\kiona\\AppData\\Roaming\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "21ab9326-8f03-4390-8d74-da5a95ddadf8",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-12-09T17:26:52.082748900Z",
     "start_time": "2025-12-09T17:26:52.072126100Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tabulate import tabulate\n",
    "from sklearn.preprocessing import normalize"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "4fc28c8d-bad6-47d1-9b7b-ead3756251ed",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-12-09T17:26:49.491925600Z",
     "start_time": "2025-12-09T17:26:47.932040100Z"
    }
   },
   "source": [
    "# Load the model\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "4e25a4ae-3aa7-42af-bd69-198b1fa855a7",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-12-09T17:26:55.505860400Z",
     "start_time": "2025-12-09T17:26:55.491803800Z"
    }
   },
   "source": [
    "# Here we can make lists for datasets we want to order\n",
    "animals = [\n",
    "    \"kitten\", \"puppy\", \"rabbit\", \"panda\", \"hedgehog\",\n",
    "    \"hamster\", \"dolphin\", \"horse\", \"penguin\",\n",
    "    \"fox\", \"deer\", \"owl\", \"cow\", \"chicken\", \"goat\",\n",
    "    \"pig\", \"parrot\", \"squirrel\", \"rat\", \"snake\", \"spider\",\n",
    "    \"bat\", \"vulture\", \"shark\", \"cockroach\", \"maggot\", \"worm\", \"hyena\",\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de2b1744-c18e-4672-b248-84176b8eac1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This combines multiple similar words into a single word anchor to remove noise\n",
    "def encode_anchor(words):\n",
    "    vecs = model.encode(words)\n",
    "    vecs = normalize(vecs)\n",
    "    mean_vec = np.mean(vecs, axis = 0)\n",
    "    mean_vec = mean_vec / np.linalg.norm(mean_vec)\n",
    "    return mean_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5eb01cc8-43bf-4850-8e9c-614d1d88c7fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This function does the projection\n",
    "def proj_meas(v1, v2, v3):\n",
    "    v = v2-v1\n",
    "    w = v3-v1\n",
    "    proj = np.dot(w,v)/np.dot(v,v)*v\n",
    "    d = np.linalg.norm(w - proj)\n",
    "    \n",
    "    t = np.dot(w, v) / np.dot(v, v) # t is how far along on the spectrum something is, 0.0 for v1, 1.0 for v2.\n",
    "    proj_point = v1 + t * v\n",
    "    return d, proj_point, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55975b35-032f-4bf0-bd54-7fa033705e87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From  ['angry', 'hostile', 'aggressive', 'mean', 'irritable']  to  ['friendly', 'nice', 'gentle', 'kind', 'affectionate'] :\n",
      "╒═══════════╤═════════════╤════════════╤═══════════════════════╕\n",
      "│ Word      │   t (scale) │   Distance │   Normalized Distance │\n",
      "╞═══════════╪═════════════╪════════════╪═══════════════════════╡\n",
      "│ squirrel  │       0.409 │      1.06  │                 0.834 │\n",
      "├───────────┼─────────────┼────────────┼───────────────────────┤\n",
      "│ cockroach │       0.411 │      1.099 │                 0.438 │\n",
      "├───────────┼─────────────┼────────────┼───────────────────────┤\n",
      "│ maggot    │       0.412 │      1.097 │                 0.452 │\n",
      "├───────────┼─────────────┼────────────┼───────────────────────┤\n",
      "│ snake     │       0.422 │      1.077 │                 0.655 │\n",
      "├───────────┼─────────────┼────────────┼───────────────────────┤\n",
      "│ vulture   │       0.429 │      1.075 │                 0.681 │\n",
      "├───────────┼─────────────┼────────────┼───────────────────────┤\n",
      "│ rat       │       0.43  │      1.05  │                 0.935 │\n",
      "├───────────┼─────────────┼────────────┼───────────────────────┤\n",
      "│ shark     │       0.451 │      1.098 │                 0.45  │\n",
      "├───────────┼─────────────┼────────────┼───────────────────────┤\n",
      "│ parrot    │       0.458 │      1.095 │                 0.476 │\n",
      "├───────────┼─────────────┼────────────┼───────────────────────┤\n",
      "│ worm      │       0.461 │      1.088 │                 0.545 │\n",
      "├───────────┼─────────────┼────────────┼───────────────────────┤\n",
      "│ chicken   │       0.463 │      1.087 │                 0.559 │\n",
      "├───────────┼─────────────┼────────────┼───────────────────────┤\n",
      "│ bat       │       0.468 │      1.05  │                 0.928 │\n",
      "├───────────┼─────────────┼────────────┼───────────────────────┤\n",
      "│ deer      │       0.473 │      1.11  │                 0.325 │\n",
      "├───────────┼─────────────┼────────────┼───────────────────────┤\n",
      "│ fox       │       0.477 │      1.111 │                 0.314 │\n",
      "├───────────┼─────────────┼────────────┼───────────────────────┤\n",
      "│ hyena     │       0.478 │      1.105 │                 0.377 │\n",
      "├───────────┼─────────────┼────────────┼───────────────────────┤\n",
      "│ penguin   │       0.484 │      1.077 │                 0.663 │\n",
      "├───────────┼─────────────┼────────────┼───────────────────────┤\n",
      "│ goat      │       0.487 │      1.055 │                 0.878 │\n",
      "├───────────┼─────────────┼────────────┼───────────────────────┤\n",
      "│ hedgehog  │       0.489 │      1.134 │                 0.077 │\n",
      "├───────────┼─────────────┼────────────┼───────────────────────┤\n",
      "│ rabbit    │       0.496 │      1.121 │                 0.212 │\n",
      "├───────────┼─────────────┼────────────┼───────────────────────┤\n",
      "│ panda     │       0.499 │      1.142 │                 0     │\n",
      "├───────────┼─────────────┼────────────┼───────────────────────┤\n",
      "│ spider    │       0.501 │      1.115 │                 0.269 │\n",
      "├───────────┼─────────────┼────────────┼───────────────────────┤\n",
      "│ cow       │       0.508 │      1.126 │                 0.16  │\n",
      "├───────────┼─────────────┼────────────┼───────────────────────┤\n",
      "│ owl       │       0.525 │      1.098 │                 0.445 │\n",
      "├───────────┼─────────────┼────────────┼───────────────────────┤\n",
      "│ pig       │       0.528 │      1.078 │                 0.651 │\n",
      "├───────────┼─────────────┼────────────┼───────────────────────┤\n",
      "│ horse     │       0.552 │      1.101 │                 0.419 │\n",
      "├───────────┼─────────────┼────────────┼───────────────────────┤\n",
      "│ hamster   │       0.58  │      1.109 │                 0.331 │\n",
      "├───────────┼─────────────┼────────────┼───────────────────────┤\n",
      "│ puppy     │       0.592 │      1.113 │                 0.29  │\n",
      "├───────────┼─────────────┼────────────┼───────────────────────┤\n",
      "│ dolphin   │       0.595 │      1.081 │                 0.614 │\n",
      "├───────────┼─────────────┼────────────┼───────────────────────┤\n",
      "│ kitten    │       0.619 │      1.043 │                 1     │\n",
      "╘═══════════╧═════════════╧════════════╧═══════════════════════╛\n"
     ]
    }
   ],
   "source": [
    "# Here I make the list and sort them based on the scale\n",
    "def make_scale_list(words1, words2, word_list):\n",
    "    scale_scores = []\n",
    "    dist_scores = []\n",
    "    vec1 = encode_anchor(words1)\n",
    "    vec2 = encode_anchor(words2)\n",
    "        \n",
    "    for word in word_list:\n",
    "        deter = model.encode(word)\n",
    "        deter = deter / np.linalg.norm(deter)\n",
    "\n",
    "        d, proj, t = proj_meas(vec1, vec2, deter)\n",
    "        scale_scores.append(t)\n",
    "        dist_scores.append(d)\n",
    "\n",
    "    scores, words, dists = zip(*sorted(zip(scale_scores, word_list, dist_scores)))\n",
    "    # normed_scores = (scores-min(scores))/(max(scores)-min(scores))\n",
    "    normed_dists = 1-(dists-min(dists))/(max(dists)-min(dists)) # Normalized makes a bit more sense here\n",
    "    # Build table\n",
    "    table = []\n",
    "    for word, score, dist, nor_dist in zip(words, scores, dists, normed_dists):\n",
    "        table.append([word, f\"{score:.3f}\", f\"{dist:.3f}\", f\"{nor_dist:.3f}\"])\n",
    "\n",
    "    headers = [\"Word\", \"t (scale)\", \"Distance\", \"Normalized Distance\"]\n",
    "    print('From ', words1, ' to ', words2, ':')\n",
    "    print(tabulate(table, headers=headers, tablefmt=\"fancy_grid\"))\n",
    "        \n",
    "make_scale_list([\"angry\", \"hostile\", \"aggressive\", \"mean\", \"irritable\"], [\"friendly\", \"nice\", \"gentle\", \"kind\", \"affectionate\"], animals)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
